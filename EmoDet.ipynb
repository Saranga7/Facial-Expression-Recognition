{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35887 entries, 0 to 35886\n",
      "Data columns (total 3 columns):\n",
      "emotion    35887 non-null int64\n",
      "pixels     35887 non-null object\n",
      "Usage      35887 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 841.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"fer2013.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training       28709\n",
      "PublicTest      3589\n",
      "PrivateTest     3589\n",
      "Name: Usage, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Usage\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test=[],[],[],[]\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    val=row['pixels'].split(\" \")\n",
    "    try:\n",
    "        if 'Training' in row['Usage']:\n",
    "            X_train.append(np.array(val,'float32'))\n",
    "            y_train.append(row['emotion'])\n",
    "            \n",
    "        elif 'PublicTest' in row['Usage']:\n",
    "            X_test.append(np.array(val,'float32'))\n",
    "            y_test.append(row['emotion'])\n",
    "    except:\n",
    "        print(f\"ERROR occured at index:{index} and row:{row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 70.,  80.,  82., ..., 106., 109.,  82.], dtype=float32),\n",
       " array([151., 150., 147., ..., 193., 183., 184.], dtype=float32)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-e69384cdb520>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train,'float32')\n",
    "y_train=np.array(y_train,'float32')\n",
    "X_test=np.array(X_test,'float32')\n",
    "y_test=np.array(y_test,'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing\n",
    "\n",
    "X_train-=np.mean(X_train,axis=0)\n",
    "X_train/=np.std(X_train,axis=0)\n",
    "\n",
    "X_test-=np.mean(X_test,axis=0)\n",
    "X_test/=np.std(X_test,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats=64\n",
    "num_labels=7\n",
    "width,height=48,48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np_utils.to_categorical(y_train,num_classes=num_labels)\n",
    "y_test=np_utils.to_categorical(y_test,num_classes=num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape(X_train.shape[0],width,height,1)\n",
    "X_test=X_test.reshape(X_test.shape[0],width,height,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
    "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Saranga\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/20\n",
      "28709/28709 [==============================] - 76s 3ms/step - loss: 1.7296 - accuracy: 0.2899 - val_loss: 1.6338 - val_accuracy: 0.3636\n",
      "Epoch 2/20\n",
      "28709/28709 [==============================] - 67s 2ms/step - loss: 1.5198 - accuracy: 0.4020 - val_loss: 1.3911 - val_accuracy: 0.4597\n",
      "Epoch 3/20\n",
      "28709/28709 [==============================] - 65s 2ms/step - loss: 1.3963 - accuracy: 0.4569 - val_loss: 1.3299 - val_accuracy: 0.4845\n",
      "Epoch 4/20\n",
      "28709/28709 [==============================] - 67s 2ms/step - loss: 1.3366 - accuracy: 0.4799 - val_loss: 1.2769 - val_accuracy: 0.5091\n",
      "Epoch 5/20\n",
      "28709/28709 [==============================] - 66s 2ms/step - loss: 1.2886 - accuracy: 0.5047 - val_loss: 1.2415 - val_accuracy: 0.5222\n",
      "Epoch 6/20\n",
      "28709/28709 [==============================] - 68s 2ms/step - loss: 1.2486 - accuracy: 0.5193 - val_loss: 1.2247 - val_accuracy: 0.5255\n",
      "Epoch 7/20\n",
      "28709/28709 [==============================] - 66s 2ms/step - loss: 1.2252 - accuracy: 0.5276 - val_loss: 1.2058 - val_accuracy: 0.5372\n",
      "Epoch 8/20\n",
      "28709/28709 [==============================] - 68s 2ms/step - loss: 1.1956 - accuracy: 0.5417 - val_loss: 1.1811 - val_accuracy: 0.5492\n",
      "Epoch 9/20\n",
      "28709/28709 [==============================] - 66s 2ms/step - loss: 1.1759 - accuracy: 0.5461 - val_loss: 1.1773 - val_accuracy: 0.5556\n",
      "Epoch 10/20\n",
      "28709/28709 [==============================] - 69s 2ms/step - loss: 1.1523 - accuracy: 0.5578 - val_loss: 1.2151 - val_accuracy: 0.5419\n",
      "Epoch 11/20\n",
      "28709/28709 [==============================] - 68s 2ms/step - loss: 1.1352 - accuracy: 0.5641 - val_loss: 1.1805 - val_accuracy: 0.5481\n",
      "Epoch 12/20\n",
      "28709/28709 [==============================] - 69s 2ms/step - loss: 1.1109 - accuracy: 0.5784 - val_loss: 1.1561 - val_accuracy: 0.5522\n",
      "Epoch 13/20\n",
      "28709/28709 [==============================] - 67s 2ms/step - loss: 1.0980 - accuracy: 0.5797 - val_loss: 1.1589 - val_accuracy: 0.5514\n",
      "Epoch 14/20\n",
      "28709/28709 [==============================] - 69s 2ms/step - loss: 1.0816 - accuracy: 0.5856 - val_loss: 1.1524 - val_accuracy: 0.5659\n",
      "Epoch 15/20\n",
      "28709/28709 [==============================] - 68s 2ms/step - loss: 1.0635 - accuracy: 0.5934 - val_loss: 1.1533 - val_accuracy: 0.5631\n",
      "Epoch 16/20\n",
      "28709/28709 [==============================] - 70s 2ms/step - loss: 1.0468 - accuracy: 0.5970 - val_loss: 1.1548 - val_accuracy: 0.5614\n",
      "Epoch 17/20\n",
      "28709/28709 [==============================] - 69s 2ms/step - loss: 1.0355 - accuracy: 0.6029 - val_loss: 1.1721 - val_accuracy: 0.5511\n",
      "Epoch 18/20\n",
      "28709/28709 [==============================] - 71s 2ms/step - loss: 1.0149 - accuracy: 0.6110 - val_loss: 1.1624 - val_accuracy: 0.5645\n",
      "Epoch 19/20\n",
      "28709/28709 [==============================] - 69s 2ms/step - loss: 1.0059 - accuracy: 0.6133 - val_loss: 1.1665 - val_accuracy: 0.5603\n",
      "Epoch 20/20\n",
      "28709/28709 [==============================] - 71s 2ms/step - loss: 0.9842 - accuracy: 0.6236 - val_loss: 1.1882 - val_accuracy: 0.5483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a7ddeef988>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=categorical_crossentropy,optimizer=Adam(),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,batch_size=64,epochs=20,verbose=1,validation_data=(X_test,y_test),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving model\n",
    "\n",
    "fer_json=model.to_json()\n",
    "with open(\"fer.json\",\"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights(\"fer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Saranga\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      " 3588096/58889256 [>.............................] - ETA: 47:38"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "model = VGG16(include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Saranga\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Saranga\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import image\n",
    "\n",
    "#load model\n",
    "model = model_from_json(open(\"fer.json\", \"r\").read())\n",
    "#load weights\n",
    "model.load_weights('fer.h5')\n",
    "\n",
    "\n",
    "face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,test_img=cap.read()# captures frame and returns boolean value and captured image\n",
    "    if not ret:\n",
    "        continue\n",
    "    gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.2,2)\n",
    "\n",
    "\n",
    "    for (x,y,w,h) in faces_detected:\n",
    "        cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)\n",
    "        roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image\n",
    "        roi_gray=cv2.resize(roi_gray,(48,48))\n",
    "        img_pixels = image.img_to_array(roi_gray)\n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "        img_pixels /= 255\n",
    "\n",
    "        predictions = model.predict(img_pixels)\n",
    "\n",
    "        #find max indexed array\n",
    "        max_index = np.argmax(predictions[0])\n",
    "\n",
    "        emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "        predicted_emotion = emotions[max_index]\n",
    "\n",
    "        cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "    resized_img = cv2.resize(test_img, (1000, 700))\n",
    "    cv2.imshow('Facial emotion analysis ',resized_img)\n",
    "    if cv2.waitKey(10) == ord('q'):#wait until 'q' key is pressed\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
